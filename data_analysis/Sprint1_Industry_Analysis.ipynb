{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint 1 - è·å…°è¡Œä¸šè–ªé…¬åˆ†æ (Dutch Industry Salary Analysis)\n",
    "\n",
    "**ç›®æ ‡**: è®¡ç®—2010-2024å¹´é—´è·å…°å„è¡Œä¸šè–ªé…¬çš„ä¸‰ä¸ªå…³é”®æŒ‡æ ‡ï¼š\n",
    "- ğŸ† **å¢é•¿å† å†› (Growth Champion)**: è–ªé…¬å¢é•¿æœ€å¿«çš„è¡Œä¸š\n",
    "- ğŸ“‰ **è¡°é€€ä¹‹ç‹ (Decline King)**: è–ªé…¬ä¸‹é™æœ€å¤šçš„è¡Œä¸š\n",
    "- ğŸ“Š **å·®è·å€æ•° (Gap Multiplier)**: 2024å¹´æœ€é«˜ä¸æœ€ä½è–ªé…¬è¡Œä¸šçš„å€æ•°å·®è·\n",
    "\n",
    "**æ•°æ®æ¥æº**: CBS (è·å…°ä¸­å¤®ç»Ÿè®¡å±€) å¼€æ”¾æ•°æ®\n",
    "**æ—¶é—´èŒƒå›´**: 2010-2024å¹´\n",
    "**åˆ›å»ºæ—¶é—´**: 2024.12.07, 23:45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“š åº“å¯¼å…¥å®Œæˆ (Libraries imported successfully)\n",
      "ğŸ¯ å¼€å§‹æ•°æ®åˆ†æä»»åŠ¡ (Starting data analysis task)\n"
     ]
    }
   ],
   "source": [
    "# å¯¼å…¥å¿…è¦çš„åº“ (Import necessary libraries) - 2024.12.07, 23:45\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# è®¾ç½®ä¸­æ–‡å­—ä½“æ”¯æŒ (Set Chinese font support)\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print('ğŸ“š åº“å¯¼å…¥å®Œæˆ (Libraries imported successfully)')\n",
    "print('ğŸ¯ å¼€å§‹æ•°æ®åˆ†æä»»åŠ¡ (Starting data analysis task)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç¬¬2é˜¶æ®µï¼šæ•°æ®åŠ è½½ä¸é¢„å¤„ç† (Phase 2: Data Loading and Preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ å¼€å§‹åŠ è½½æ•°æ®æ–‡ä»¶...\n",
      "âœ… æˆåŠŸåŠ è½½ ../data_acquisition/raw_data/TypedDataSet.jsonï¼Œå…± 3000 æ¡è®°å½•\n",
      "âœ… æˆåŠŸåŠ è½½ ../data_acquisition/raw_data/SectorBranchesSIC2008.jsonï¼Œå…± 100 æ¡è®°å½•\n",
      "âœ… æˆåŠŸåŠ è½½ ../data_acquisition/raw_data/Periods.jsonï¼Œå…± 30 æ¡è®°å½•\n",
      "ğŸ“Š æ•°æ®åŠ è½½å®Œæˆ (Data loading completed)\n"
     ]
    }
   ],
   "source": [
    "# ä»»åŠ¡ 2.1: æ­£ç¡®åŠ è½½JSONæ•°æ® (Correctly Load JSON Data) - 2024.12.07, 23:46\n",
    "\n",
    "def load_typed_dataset(file_path):\n",
    "    \"\"\"\n",
    "    åŠ è½½TypedDataSet.jsonæ–‡ä»¶ (Load TypedDataSet.json file)\n",
    "    æ³¨æ„ï¼šè¿™æ˜¯ä¸€ä¸ªåˆ—è¡¨ç»“æ„ï¼Œä¸æ˜¯å­—å…¸ (Note: This is a list structure, not a dictionary)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            typed_data = json.load(f)  # ç›´æ¥åŠ è½½åˆ—è¡¨ (Load list directly)\n",
    "        df = pd.DataFrame(typed_data)\n",
    "        print(f'âœ… æˆåŠŸåŠ è½½ {file_path}ï¼Œå…± {len(df)} æ¡è®°å½•')\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f'âŒ åŠ è½½å¤±è´¥: {e}')\n",
    "        return None\n",
    "\n",
    "def load_auxiliary_data(file_path):\n",
    "    \"\"\"åŠ è½½è¾…åŠ©æ•°æ®æ–‡ä»¶ (Load auxiliary data files)\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        df = pd.DataFrame(data)\n",
    "        print(f'âœ… æˆåŠŸåŠ è½½ {file_path}ï¼Œå…± {len(df)} æ¡è®°å½•')\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f'âŒ åŠ è½½å¤±è´¥: {e}')\n",
    "        return None\n",
    "\n",
    "# è®¾ç½®æ•°æ®æ–‡ä»¶è·¯å¾„ (Set data file paths)\n",
    "data_dir = Path('../data_acquisition/raw_data')\n",
    "\n",
    "# åŠ è½½ä¸»æ•°æ®é›† (Load main dataset)\n",
    "print('ğŸ”„ å¼€å§‹åŠ è½½æ•°æ®æ–‡ä»¶...')\n",
    "typed_df = load_typed_dataset(data_dir / 'TypedDataSet.json')\n",
    "\n",
    "# åŠ è½½è¾…åŠ©æ•°æ® (Load auxiliary data)\n",
    "sectors_df = load_auxiliary_data(data_dir / 'SectorBranchesSIC2008.json')\n",
    "periods_df = load_auxiliary_data(data_dir / 'Periods.json')\n",
    "\n",
    "print('ğŸ“Š æ•°æ®åŠ è½½å®Œæˆ (Data loading completed)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‹ æ•°æ®ç»“æ„åˆ†æ (Data Structure Analysis)\n",
      "æ•°æ®å½¢çŠ¶: (3000, 39)\n",
      "åˆ—æ•°é‡: 39\n",
      "å‰5åˆ—åç§°:\n",
      "  1. ID\n",
      "  2. SectorBranchesSIC2008\n",
      "  3. Periods\n",
      "  4. CompensationOfEmployees_1\n",
      "  5. WagesAndSalaries_2\n",
      "ğŸ’° å‘ç° 12 ä¸ªè–ªé…¬ç›¸å…³åˆ—:\n",
      "  - CompensationOfEmployees_1\n",
      "  - WagesAndSalaries_2\n",
      "  - CompensationOfEmployees_5\n",
      "ğŸ” æœ‰ç©ºå€¼çš„åˆ—æ•°é‡: 36\n",
      "ğŸ§¹ å¼€å§‹æ•°æ®æ¸…ç† (Starting data cleaning)\n",
      "âœ… å·²è½¬æ¢ 12 ä¸ªè–ªé…¬åˆ—ä¸ºæ•°å€¼ç±»å‹\n",
      "ä¸»è¦è–ªé…¬åˆ— CompensationOfEmployees_1 æœ‰æ•ˆæ•°æ®: 2940/3000 (98.0%)\n",
      "âœ¨ æ•°æ®æ¸…ç†å®Œæˆ (Data cleaning completed)\n"
     ]
    }
   ],
   "source": [
    "# ä»»åŠ¡ 2.2: æ•°æ®ç»“æ„åˆ†æä¸æ¸…ç† (Data Structure Analysis and Cleaning) - 2024.12.07, 23:47\n",
    "\n",
    "def analyze_data_structure(df):\n",
    "    \"\"\"åˆ†ææ•°æ®ç»“æ„ (Analyze data structure)\"\"\"\n",
    "    print('ğŸ“‹ æ•°æ®ç»“æ„åˆ†æ (Data Structure Analysis)')\n",
    "    print(f'æ•°æ®å½¢çŠ¶: {df.shape}')\n",
    "    print(f'åˆ—æ•°é‡: {len(df.columns)}')\n",
    "    print('å‰5åˆ—åç§°:')\n",
    "    for i, col in enumerate(df.columns[:5]):\n",
    "        print(f'  {i+1}. {col}')\n",
    "    \n",
    "    # æŸ¥æ‰¾è–ªé…¬ç›¸å…³åˆ— (Find salary-related columns)\n",
    "    salary_cols = [col for col in df.columns if 'Compensation' in col or 'Wages' in col]\n",
    "    print(f'ğŸ’° å‘ç° {len(salary_cols)} ä¸ªè–ªé…¬ç›¸å…³åˆ—:')\n",
    "    for col in salary_cols[:3]:  # æ˜¾ç¤ºå‰3ä¸ª\n",
    "        print(f'  - {col}')\n",
    "    \n",
    "    # æ£€æŸ¥ç©ºå€¼åˆ†å¸ƒ (Check null value distribution)\n",
    "    null_counts = df.isnull().sum()\n",
    "    non_zero_nulls = null_counts[null_counts > 0]\n",
    "    print(f'ğŸ” æœ‰ç©ºå€¼çš„åˆ—æ•°é‡: {len(non_zero_nulls)}')\n",
    "    \n",
    "    return salary_cols\n",
    "\n",
    "def clean_salary_data(df, salary_cols):\n",
    "    \"\"\"æ¸…ç†è–ªé…¬æ•°æ® (Clean salary data)\"\"\"\n",
    "    print('ğŸ§¹ å¼€å§‹æ•°æ®æ¸…ç† (Starting data cleaning)')\n",
    "    \n",
    "    # è½¬æ¢è–ªé…¬åˆ—ä¸ºæ•°å€¼ç±»å‹ (Convert salary columns to numeric)\n",
    "    for col in salary_cols:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    \n",
    "    print(f'âœ… å·²è½¬æ¢ {len(salary_cols)} ä¸ªè–ªé…¬åˆ—ä¸ºæ•°å€¼ç±»å‹')\n",
    "    \n",
    "    # æ£€æŸ¥è½¬æ¢åçš„æ•°æ®è´¨é‡ (Check data quality after conversion)\n",
    "    main_salary_col = 'CompensationOfEmployees_1'\n",
    "    if main_salary_col in df.columns:\n",
    "        valid_data = df[main_salary_col].notna()\n",
    "        print(f'ä¸»è¦è–ªé…¬åˆ— {main_salary_col} æœ‰æ•ˆæ•°æ®: {valid_data.sum()}/{len(df)} ({valid_data.mean():.1%})')\n",
    "    \n",
    "    return df\n",
    "\n",
    "# æ‰§è¡Œæ•°æ®ç»“æ„åˆ†æ (Execute data structure analysis)\n",
    "if typed_df is not None:\n",
    "    salary_columns = analyze_data_structure(typed_df)\n",
    "    typed_df_clean = clean_salary_data(typed_df.copy(), salary_columns)\n",
    "    print('âœ¨ æ•°æ®æ¸…ç†å®Œæˆ (Data cleaning completed)')\n",
    "else:\n",
    "    print('âŒ æ— æ³•è¿›è¡Œæ•°æ®åˆ†æï¼Œä¸»æ•°æ®é›†åŠ è½½å¤±è´¥')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ­ å¼€å§‹è¡Œä¸šæ˜ å°„ (Starting industry mapping)\n",
      "ä¸»æ•°æ®é›†åˆ—å: ['ID', 'SectorBranchesSIC2008', 'Periods', 'CompensationOfEmployees_1', 'WagesAndSalaries_2']\n",
      "è¡Œä¸šæ•°æ®é›†åˆ—å: ['Key', 'Title', 'Description', 'CategoryGroupID']\n",
      "åˆ›å»ºäº† 100 ä¸ªè¡Œä¸šæ˜ å°„\n",
      "æˆåŠŸæ˜ å°„ 3000/3000 æ¡è®°å½• (100.0%)\n",
      "ğŸ“… å¼€å§‹æ—¶é—´æ˜ å°„ (Starting period mapping)\n",
      "åˆ›å»ºäº† 30 ä¸ªæ—¶é—´æ˜ å°„\n",
      "æˆåŠŸæ˜ å°„ 3000/3000 ä¸ªå¹´ä»½\n",
      "å¹´ä»½èŒƒå›´: 1995 - 2024\n",
      "ğŸ‰ æ•°æ®æ•´åˆå®Œæˆ (Data integration completed)\n",
      "æœ€ç»ˆæ•°æ®é›†å½¢çŠ¶: (3000, 41)\n"
     ]
    }
   ],
   "source": [
    "# ä»»åŠ¡ 2.3: è¡Œä¸šæ˜ å°„ä¸æ•°æ®æ•´åˆ (Industry Mapping and Data Integration) - 2024.12.07, 23:48\n",
    "\n",
    "def map_industries(main_df, sector_df):\n",
    "    \"\"\"æ˜ å°„è¡Œä¸šä»£ç åˆ°è¡Œä¸šåç§° (Map industry codes to industry names)\"\"\"\n",
    "    print('ğŸ­ å¼€å§‹è¡Œä¸šæ˜ å°„ (Starting industry mapping)')\n",
    "    \n",
    "    # æ£€æŸ¥æ˜ å°„å­—æ®µ (Check mapping fields)\n",
    "    print('ä¸»æ•°æ®é›†åˆ—å:', main_df.columns.tolist()[:5])\n",
    "    print('è¡Œä¸šæ•°æ®é›†åˆ—å:', sector_df.columns.tolist())\n",
    "    \n",
    "    # åˆ›å»ºè¡Œä¸šæ˜ å°„å­—å…¸ (Create industry mapping dictionary)\n",
    "    sector_mapping = dict(zip(sector_df['Key'], sector_df['Title']))\n",
    "    print(f'åˆ›å»ºäº† {len(sector_mapping)} ä¸ªè¡Œä¸šæ˜ å°„')\n",
    "    \n",
    "    # åº”ç”¨æ˜ å°„ (Apply mapping)\n",
    "    main_df['IndustryName'] = main_df['SectorBranchesSIC2008'].map(sector_mapping)\n",
    "    \n",
    "    # æ£€æŸ¥æ˜ å°„ç»“æœ (Check mapping results)\n",
    "    mapped_count = main_df['IndustryName'].notna().sum()\n",
    "    print(f'æˆåŠŸæ˜ å°„ {mapped_count}/{len(main_df)} æ¡è®°å½• ({mapped_count/len(main_df):.1%})')\n",
    "    \n",
    "    return main_df\n",
    "\n",
    "def map_periods(df, periods_df):\n",
    "    \"\"\"æ˜ å°„æ—¶é—´å‘¨æœŸåˆ°å¹´ä»½ (Map periods to years)\"\"\"\n",
    "    print('ğŸ“… å¼€å§‹æ—¶é—´æ˜ å°„ (Starting period mapping)')\n",
    "    \n",
    "    # åˆ›å»ºæ—¶é—´æ˜ å°„å­—å…¸ (Create period mapping dictionary)\n",
    "    period_mapping = dict(zip(periods_df['Key'], periods_df['Title']))\n",
    "    print(f'åˆ›å»ºäº† {len(period_mapping)} ä¸ªæ—¶é—´æ˜ å°„')\n",
    "    \n",
    "    # åº”ç”¨æ˜ å°„ (Apply mapping)\n",
    "    df['Year'] = df['Periods'].map(period_mapping)\n",
    "    \n",
    "    # è½¬æ¢å¹´ä»½ä¸ºæ•´æ•° (Convert year to integer)\n",
    "    df['Year'] = pd.to_numeric(df['Year'], errors='coerce')\n",
    "    \n",
    "    # æ£€æŸ¥æ˜ å°„ç»“æœ (Check mapping results)\n",
    "    valid_years = df['Year'].notna().sum()\n",
    "    print(f'æˆåŠŸæ˜ å°„ {valid_years}/{len(df)} ä¸ªå¹´ä»½')\n",
    "    \n",
    "    # æ˜¾ç¤ºå¹´ä»½èŒƒå›´ (Show year range)\n",
    "    if valid_years > 0:\n",
    "        year_range = f\"{df['Year'].min():.0f} - {df['Year'].max():.0f}\"\n",
    "        print(f'å¹´ä»½èŒƒå›´: {year_range}')\n",
    "    \n",
    "    return df\n",
    "\n",
    "# æ‰§è¡Œæ˜ å°„æ“ä½œ (Execute mapping operations)\n",
    "if all([typed_df_clean is not None, sectors_df is not None, periods_df is not None]):\n",
    "    # è¡Œä¸šæ˜ å°„ (Industry mapping)\n",
    "    typed_df_mapped = map_industries(typed_df_clean, sectors_df)\n",
    "    \n",
    "    # æ—¶é—´æ˜ å°„ (Period mapping)\n",
    "    typed_df_final = map_periods(typed_df_mapped, periods_df)\n",
    "    \n",
    "    print('ğŸ‰ æ•°æ®æ•´åˆå®Œæˆ (Data integration completed)')\n",
    "    print(f'æœ€ç»ˆæ•°æ®é›†å½¢çŠ¶: {typed_df_final.shape}')\n",
    "else:\n",
    "    print('âŒ æ— æ³•è¿›è¡Œæ•°æ®æ•´åˆï¼Œç¼ºå°‘å¿…è¦çš„æ•°æ®é›†')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç¬¬3é˜¶æ®µï¼šæ ¸å¿ƒæŒ‡æ ‡è®¡ç®— (Phase 3: Core Metric Calculation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ ç­›é€‰ç›®æ ‡å¹´ä»½: [2010, 2024]\n",
      "ç­›é€‰ç»“æœ: 200 æ¡è®°å½•\n",
      "å„å¹´ä»½è®°å½•æ•°:\n",
      "  2010: 100 æ¡è®°å½•\n",
      "  2024: 100 æ¡è®°å½•\n",
      "ğŸ” éªŒè¯æ•°æ®è´¨é‡ (Validating data quality)\n",
      "  2010å¹´: 98/100 æ¡æœ‰æ•ˆè–ªé…¬æ•°æ® (98.0%)\n",
      "  2024å¹´: 98/100 æ¡æœ‰æ•ˆè–ªé…¬æ•°æ® (98.0%)\n",
      "ğŸ“Š æ•°æ®è¦†ç›–æƒ…å†µ:\n",
      "  2010å¹´è¡Œä¸šæ•°: 100\n",
      "  2024å¹´è¡Œä¸šæ•°: 100\n",
      "  å…±åŒè¡Œä¸šæ•°: 100\n",
      "âœ… æ‰¾åˆ° 100 ä¸ªå¯æ¯”è¾ƒçš„è¡Œ\n"
     ]
    }
   ],
   "source": [
    "# ä»»åŠ¡ 3.1: ç­›é€‰2010-2024å¹´æ•°æ® (Filter 2010-2024 Data) - 2024.12.07, 23:49\n",
    "\n",
    "def filter_target_years(df, target_years=[2010, 2024]):\n",
    "    \"\"\"ç­›é€‰ç›®æ ‡å¹´ä»½æ•°æ® (Filter target year data)\"\"\"\n",
    "    print(f'ğŸ¯ ç­›é€‰ç›®æ ‡å¹´ä»½: {target_years}')\n",
    "    \n",
    "    # ç­›é€‰ç›®æ ‡å¹´ä»½ (Filter target years)\n",
    "    filtered_df = df[df['Year'].isin(target_years)].copy()\n",
    "    \n",
    "    print(f'ç­›é€‰ç»“æœ: {len(filtered_df)} æ¡è®°å½•')\n",
    "    \n",
    "    # æŒ‰å¹´ä»½ç»Ÿè®¡ (Statistics by year)\n",
    "    year_counts = filtered_df['Year'].value_counts().sort_index()\n",
    "    print('å„å¹´ä»½è®°å½•æ•°:')\n",
    "    for year, count in year_counts.items():\n",
    "        print(f'  {year}: {count} æ¡è®°å½•')\n",
    "    \n",
    "    return filtered_df\n",
    "\n",
    "def validate_year_data(filtered_df, salary_col='CompensationOfEmployees_1'):\n",
    "    \"\"\"éªŒè¯å¹´ä»½æ•°æ®è´¨é‡ (Validate year data quality)\"\"\"\n",
    "    print('ğŸ” éªŒè¯æ•°æ®è´¨é‡ (Validating data quality)')\n",
    "    \n",
    "    # æ£€æŸ¥æ¯å¹´æœ‰æ•ˆè–ªé…¬æ•°æ® (Check valid salary data per year)\n",
    "    for year in sorted(filtered_df['Year'].unique()):\n",
    "        year_data = filtered_df[filtered_df['Year'] == year]\n",
    "        valid_salary = year_data[salary_col].notna().sum()\n",
    "        total_records = len(year_data)\n",
    "        print(f'  {year}å¹´: {valid_salary}/{total_records} æ¡æœ‰æ•ˆè–ªé…¬æ•°æ® ({valid_salary/total_records:.1%})')\n",
    "    \n",
    "    # æ‰¾å‡ºä¸¤å¹´éƒ½æœ‰æ•°æ®çš„è¡Œä¸š (Find industries with data in both years)\n",
    "    industries_2010 = set(filtered_df[filtered_df['Year'] == 2010]['IndustryName'].dropna())\n",
    "    industries_2024 = set(filtered_df[filtered_df['Year'] == 2024]['IndustryName'].dropna())\n",
    "    common_industries = industries_2010.intersection(industries_2024)\n",
    "    \n",
    "    print(f'ğŸ“Š æ•°æ®è¦†ç›–æƒ…å†µ:')\n",
    "    print(f'  2010å¹´è¡Œä¸šæ•°: {len(industries_2010)}')\n",
    "    print(f'  2024å¹´è¡Œä¸šæ•°: {len(industries_2024)}')\n",
    "    print(f'  å…±åŒè¡Œä¸šæ•°: {len(common_industries)}')\n",
    "    \n",
    "    return list(common_industries)\n",
    "\n",
    "# æ‰§è¡Œå¹´ä»½ç­›é€‰å’ŒéªŒè¯ (Execute year filtering and validation)\n",
    "if 'typed_df_final' in locals() and typed_df_final is not None:\n",
    "    target_data = filter_target_years(typed_df_final)\n",
    "    common_industries = validate_year_data(target_data)\n",
    "    print(f'âœ… æ‰¾åˆ° {len(common_industries)} ä¸ªå¯æ¯”è¾ƒçš„è¡Œ')\n",
    "else:\n",
    "    print('âŒ æ— æ³•è¿›è¡Œå¹´ä»½ç­›é€‰ï¼Œæ•°æ®æ•´åˆæœªå®Œæˆ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ˆ è®¡ç®—è–ªé…¬å¢é•¿ç‡ (Calculating compensation growth rate)\n",
      "æˆåŠŸè®¡ç®— 98 ä¸ªè¡Œä¸šçš„å¢é•¿ç‡\n",
      "ğŸ† æ’åºå¢é•¿è¡¨ç° (Ranking growth performance)\n",
      "å¢é•¿ç‡ç»Ÿè®¡:\n",
      "  æœ€é«˜: 237.6%\n",
      "  æœ€ä½: -39.4%\n",
      "  å¹³å‡: 64.9%\n",
      "  ä¸­ä½æ•°: 64.6%\n",
      "ğŸ” å¢é•¿æœ€å¿«çš„5ä¸ªè¡Œä¸š:\n",
      "  1. 79 Travel agencies, tour operators etc: 237.6%\n",
      "  2. T Activities of households: 165.3%\n",
      "  3. 62-63 IT- and information services: 158.4%\n",
      "  4. 28 Manufacture of machinery n.e.c.: 133.1%\n",
      "  5. 77 Renting and leasing of tangible goods: 131.2%\n",
      "ğŸ“‰ å¢é•¿æœ€æ…¢çš„5ä¸ªè¡Œä¸š:\n",
      "  5. B Mining and quarrying: 10.9%\n",
      "  4. 65 Insurance and pension funding: 5.9%\n",
      "  3. 16-18 Man. wood en paperprod., printing: 4.8%\n",
      "  2. 58 Publishing: -3.1%\n",
      "  1. 18 Printing and reproduction: -39.4%\n",
      "âœ… å¢é•¿ç‡è®¡ç®—å®Œæˆ\n"
     ]
    }
   ],
   "source": [
    "# ä»»åŠ¡ 3.2: è®¡ç®—è–ªé…¬å¢é•¿ç‡ (Calculate Compensation Growth Rate) - 2024.12.07, 23:50\n",
    "\n",
    "def calculate_industry_growth(df, salary_col='CompensationOfEmployees_1'):\n",
    "    \"\"\"è®¡ç®—è¡Œä¸šè–ªé…¬å¢é•¿ç‡ (Calculate industry compensation growth rate)\"\"\"\n",
    "    print('ğŸ“ˆ è®¡ç®—è–ªé…¬å¢é•¿ç‡ (Calculating compensation growth rate)')\n",
    "    \n",
    "    # åˆ›å»ºé€è§†è¡¨ (Create pivot table)\n",
    "    pivot_df = df.pivot_table(\n",
    "        index='IndustryName',\n",
    "        columns='Year',\n",
    "        values=salary_col,\n",
    "        aggfunc='first'\n",
    "    ).reset_index()\n",
    "    \n",
    "    # é‡å‘½ååˆ— (Rename columns)\n",
    "    pivot_df.columns.name = None\n",
    "    if 2010.0 in pivot_df.columns and 2024.0 in pivot_df.columns:\n",
    "        pivot_df = pivot_df.rename(columns={2010.0: 'Salary_2010', 2024.0: 'Salary_2024'})\n",
    "    \n",
    "    # è¿‡æ»¤æœ‰æ•ˆæ•°æ® (Filter valid data)\n",
    "    valid_data = pivot_df.dropna(subset=['Salary_2010', 'Salary_2024'])\n",
    "    \n",
    "    # è®¡ç®—å¢é•¿æŒ‡æ ‡ (Calculate growth metrics)\n",
    "    valid_data['Absolute_Growth'] = valid_data['Salary_2024'] - valid_data['Salary_2010']\n",
    "    valid_data['Growth_Rate'] = (valid_data['Salary_2024'] - valid_data['Salary_2010']) / valid_data['Salary_2010'] * 100\n",
    "    \n",
    "    print(f'æˆåŠŸè®¡ç®— {len(valid_data)} ä¸ªè¡Œä¸šçš„å¢é•¿ç‡')\n",
    "    \n",
    "    return valid_data\n",
    "\n",
    "def rank_growth_performance(growth_df):\n",
    "    \"\"\"æ’åºå¢é•¿è¡¨ç° (Rank growth performance)\"\"\"\n",
    "    print('ğŸ† æ’åºå¢é•¿è¡¨ç° (Ranking growth performance)')\n",
    "    \n",
    "    # æŒ‰å¢é•¿ç‡æ’åº (Sort by growth rate)\n",
    "    ranked_df = growth_df.sort_values('Growth_Rate', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯ (Show statistics)\n",
    "    print(f'å¢é•¿ç‡ç»Ÿè®¡:')\n",
    "    print(f'  æœ€é«˜: {ranked_df[\"Growth_Rate\"].max():.1f}%')\n",
    "    print(f'  æœ€ä½: {ranked_df[\"Growth_Rate\"].min():.1f}%')\n",
    "    print(f'  å¹³å‡: {ranked_df[\"Growth_Rate\"].mean():.1f}%')\n",
    "    print(f'  ä¸­ä½æ•°: {ranked_df[\"Growth_Rate\"].median():.1f}%')\n",
    "    \n",
    "    # æ˜¾ç¤ºå‰5å’Œå5 (Show top 5 and bottom 5)\n",
    "    print('ğŸ” å¢é•¿æœ€å¿«çš„5ä¸ªè¡Œä¸š:')\n",
    "    for i, row in ranked_df.head().iterrows():\n",
    "        print(f'  {i+1}. {row[\"IndustryName\"]}: {row[\"Growth_Rate\"]:.1f}%')\n",
    "    \n",
    "    print('ğŸ“‰ å¢é•¿æœ€æ…¢çš„5ä¸ªè¡Œä¸š:')\n",
    "    for i, row in ranked_df.tail().iterrows():\n",
    "        print(f'  {len(ranked_df)-i}. {row[\"IndustryName\"]}: {row[\"Growth_Rate\"]:.1f}%')\n",
    "    \n",
    "    return ranked_df\n",
    "\n",
    "# æ‰§è¡Œå¢é•¿ç‡è®¡ç®— (Execute growth rate calculation)\n",
    "if 'target_data' in locals() and target_data is not None:\n",
    "    growth_data = calculate_industry_growth(target_data)\n",
    "    ranked_growth = rank_growth_performance(growth_data)\n",
    "    print('âœ… å¢é•¿ç‡è®¡ç®—å®Œæˆ')\n",
    "else:\n",
    "    print('âŒ æ— æ³•è®¡ç®—å¢é•¿ç‡ï¼Œç›®æ ‡æ•°æ®æœªå‡†å¤‡å¥½')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ† å¢é•¿å† å†› (Growth Champion):\n",
      "  è¡Œä¸š: 79 Travel agencies, tour operators etc\n",
      "  2010å¹´è–ªé…¬: â‚¬675\n",
      "  2024å¹´è–ªé…¬: â‚¬2,279\n",
      "  ç»å¯¹å¢é•¿: â‚¬1,604\n",
      "  å¢é•¿ç‡: 237.6%\n",
      "ğŸ“‰ è¡°é€€ä¹‹ç‹ (Decline King):\n",
      "  è¡Œä¸š: 18 Printing and reproduction\n",
      "  2010å¹´è–ªé…¬: â‚¬1,228\n",
      "  2024å¹´è–ªé…¬: â‚¬744\n",
      "  ç»å¯¹å˜åŒ–: â‚¬-484\n",
      "  å˜åŒ–ç‡: -39.4%\n",
      "âœ… å† å†›è¯†åˆ«å®Œæˆ\n"
     ]
    }
   ],
   "source": [
    "# ä»»åŠ¡ 3.3: è¯†åˆ«å¢é•¿å† å†›å’Œè¡°é€€ä¹‹ç‹ (Identify Growth Champions and Decline Kings) - 2024.12.07, 23:51\n",
    "\n",
    "def identify_growth_champion(growth_df):\n",
    "    \"\"\"è¯†åˆ«å¢é•¿å† å†› (Identify growth champion)\"\"\"\n",
    "    champion = growth_df.loc[growth_df['Growth_Rate'].idxmax()]\n",
    "    \n",
    "    print('ğŸ† å¢é•¿å† å†› (Growth Champion):')\n",
    "    print(f'  è¡Œä¸š: {champion[\"IndustryName\"]}')\n",
    "    print(f'  2010å¹´è–ªé…¬: â‚¬{champion[\"Salary_2010\"]:,.0f}')\n",
    "    print(f'  2024å¹´è–ªé…¬: â‚¬{champion[\"Salary_2024\"]:,.0f}')\n",
    "    print(f'  ç»å¯¹å¢é•¿: â‚¬{champion[\"Absolute_Growth\"]:,.0f}')\n",
    "    print(f'  å¢é•¿ç‡: {champion[\"Growth_Rate\"]:.1f}%')\n",
    "    \n",
    "    return champion\n",
    "\n",
    "def identify_decline_king(growth_df):\n",
    "    \"\"\"è¯†åˆ«è¡°é€€ä¹‹ç‹ (Identify decline king)\"\"\"\n",
    "    decline_king = growth_df.loc[growth_df['Growth_Rate'].idxmin()]\n",
    "    \n",
    "    print('ğŸ“‰ è¡°é€€ä¹‹ç‹ (Decline King):')\n",
    "    print(f'  è¡Œä¸š: {decline_king[\"IndustryName\"]}')\n",
    "    print(f'  2010å¹´è–ªé…¬: â‚¬{decline_king[\"Salary_2010\"]:,.0f}')\n",
    "    print(f'  2024å¹´è–ªé…¬: â‚¬{decline_king[\"Salary_2024\"]:,.0f}')\n",
    "    print(f'  ç»å¯¹å˜åŒ–: â‚¬{decline_king[\"Absolute_Growth\"]:,.0f}')\n",
    "    print(f'  å˜åŒ–ç‡: {decline_king[\"Growth_Rate\"]:.1f}%')\n",
    "    \n",
    "    return decline_king\n",
    "\n",
    "# æ‰§è¡Œå† å†›è¯†åˆ« (Execute champion identification)\n",
    "if 'ranked_growth' in locals() and ranked_growth is not None:\n",
    "    growth_champion = identify_growth_champion(ranked_growth)\n",
    "    decline_king = identify_decline_king(ranked_growth)\n",
    "    print('âœ… å† å†›è¯†åˆ«å®Œæˆ')\n",
    "else:\n",
    "    print('âŒ æ— æ³•è¯†åˆ«å† å†›ï¼Œå¢é•¿æ•°æ®æœªå‡†å¤‡å¥½')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’° åˆ†æ2024å¹´è–ªé…¬åˆ†å¸ƒ (Analyzing 2024 salary distribution)\n",
      "ğŸ’ æœ€é«˜è–ªé…¬è¡Œä¸š: A-U All economic activities\n",
      "    è–ªé…¬: â‚¬525,311\n",
      "ğŸ’§ æœ€ä½è–ªé…¬è¡Œä¸š: 03 Fishing and aquaculture\n",
      "    è–ªé…¬: â‚¬116\n",
      "ğŸ“Š 2024å¹´è–ªé…¬å·®è·å€æ•° (2024 Salary Gap Multiplier):\n",
      "  æœ€é«˜è–ªé…¬: â‚¬525,311 (A-U All economic activities)\n",
      "  æœ€ä½è–ªé…¬: â‚¬116 (03 Fishing and aquaculture)\n",
      "  å·®è·å€æ•°: 4528.5x\n",
      "  è§£é‡Š: æœ€é«˜è–ªé…¬è¡Œä¸šçš„è–ªé…¬æ˜¯æœ€ä½è–ªé…¬è¡Œä¸šçš„ 4528.5 å€\n",
      "âœ… å·®è·å€æ•°è®¡ç®—å®Œæˆ\n"
     ]
    }
   ],
   "source": [
    "# ä»»åŠ¡ 3.4: è®¡ç®—2024å¹´è–ªé…¬å·®è·å€æ•° (Calculate 2024 Salary Gap Multiplier) - 2024.12.07, 23:52\n",
    "\n",
    "def find_salary_extremes_2024(df, salary_col='CompensationOfEmployees_1'):\n",
    "    \"\"\"æ‰¾å‡º2024å¹´è–ªé…¬æå€¼ (Find 2024 salary extremes)\"\"\"\n",
    "    print('ğŸ’° åˆ†æ2024å¹´è–ªé…¬åˆ†å¸ƒ (Analyzing 2024 salary distribution)')\n",
    "    \n",
    "    # ç­›é€‰2024å¹´æ•°æ® (Filter 2024 data)\n",
    "    data_2024 = df[df['Year'] == 2024].copy()\n",
    "    \n",
    "    # ç§»é™¤ç©ºå€¼ (Remove null values)\n",
    "    valid_2024 = data_2024.dropna(subset=[salary_col, 'IndustryName'])\n",
    "    \n",
    "    if len(valid_2024) == 0:\n",
    "        print('âŒ æ²¡æœ‰æ‰¾åˆ°2024å¹´çš„æœ‰æ•ˆè–ªé…¬æ•°æ®')\n",
    "        return None, None\n",
    "    \n",
    "    # æ‰¾å‡ºæœ€é«˜å’Œæœ€ä½è–ªé…¬ (Find highest and lowest salaries)\n",
    "    highest_idx = valid_2024[salary_col].idxmax()\n",
    "    lowest_idx = valid_2024[salary_col].idxmin()\n",
    "    \n",
    "    highest_salary_row = valid_2024.loc[highest_idx]\n",
    "    lowest_salary_row = valid_2024.loc[lowest_idx]\n",
    "    \n",
    "    print(f'ğŸ’ æœ€é«˜è–ªé…¬è¡Œä¸š: {highest_salary_row[\"IndustryName\"]}')\n",
    "    print(f'    è–ªé…¬: â‚¬{highest_salary_row[salary_col]:,.0f}')\n",
    "    \n",
    "    print(f'ğŸ’§ æœ€ä½è–ªé…¬è¡Œä¸š: {lowest_salary_row[\"IndustryName\"]}')\n",
    "    print(f'    è–ªé…¬: â‚¬{lowest_salary_row[salary_col]:,.0f}')\n",
    "    \n",
    "    return highest_salary_row, lowest_salary_row\n",
    "\n",
    "def calculate_gap_multiplier(highest_row, lowest_row, salary_col='CompensationOfEmployees_1'):\n",
    "    \"\"\"è®¡ç®—å·®è·å€æ•° (Calculate gap multiplier)\"\"\"\n",
    "    if highest_row is None or lowest_row is None:\n",
    "        return None\n",
    "    \n",
    "    highest_salary = highest_row[salary_col]\n",
    "    lowest_salary = lowest_row[salary_col]\n",
    "    \n",
    "    if lowest_salary == 0:\n",
    "        print('âŒ æœ€ä½è–ªé…¬ä¸º0ï¼Œæ— æ³•è®¡ç®—å€æ•°')\n",
    "        return None\n",
    "    \n",
    "    gap_multiplier = highest_salary / lowest_salary\n",
    "    \n",
    "    print(f'ğŸ“Š 2024å¹´è–ªé…¬å·®è·å€æ•° (2024 Salary Gap Multiplier):')\n",
    "    print(f'  æœ€é«˜è–ªé…¬: â‚¬{highest_salary:,.0f} ({highest_row[\"IndustryName\"]})') \n",
    "    print(f'  æœ€ä½è–ªé…¬: â‚¬{lowest_salary:,.0f} ({lowest_row[\"IndustryName\"]})') \n",
    "    print(f'  å·®è·å€æ•°: {gap_multiplier:.1f}x')\n",
    "    print(f'  è§£é‡Š: æœ€é«˜è–ªé…¬è¡Œä¸šçš„è–ªé…¬æ˜¯æœ€ä½è–ªé…¬è¡Œä¸šçš„ {gap_multiplier:.1f} å€')\n",
    "    \n",
    "    return gap_multiplier\n",
    "\n",
    "# æ‰§è¡Œå·®è·è®¡ç®— (Execute gap calculation)\n",
    "if 'target_data' in locals() and target_data is not None:\n",
    "    highest_2024, lowest_2024 = find_salary_extremes_2024(target_data)\n",
    "    gap_multiplier = calculate_gap_multiplier(highest_2024, lowest_2024)\n",
    "    print('âœ… å·®è·å€æ•°è®¡ç®—å®Œæˆ')\n",
    "else:\n",
    "    print('âŒ æ— æ³•è®¡ç®—å·®è·å€æ•°ï¼Œç›®æ ‡æ•°æ®æœªå‡†å¤‡å¥½')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“‹ æœ€ç»ˆç»“æœæ±‡æ€» (Final Results Summary)\n",
    "\n",
    "### ğŸ¯ ä¸‰ä¸ªå…³é”®æ•°å­— (Three Key Numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‰ === è·å…°è¡Œä¸šè–ªé…¬åˆ†ææœ€ç»ˆç»“æœ (Final Results) === ğŸ‰\n",
      "\n",
      "============================================================\n",
      "âœ… æ•°æ®åˆ†æå®Œæˆï¼è¿™äº›æ•°å­—å¯ä»¥ç”¨äºå‰ç«¯å±•ç¤ºã€‚\n",
      "ğŸ“Š åˆ†æåŸºäºCBSè·å…°ä¸­å¤®ç»Ÿè®¡å±€2010-2024å¹´æ•°æ®\n"
     ]
    }
   ],
   "source": [
    "# æœ€ç»ˆç»“æœæ±‡æ€» (Final Results Summary) - 2024.12.07, 23:53\n",
    "\n",
    "def summarize_big_numbers():\n",
    "    \"\"\"æ±‡æ€»ä¸‰ä¸ªå…³é”®æ•°å­— (Summarize three key numbers)\"\"\"\n",
    "    print('ğŸ‰ === è·å…°è¡Œä¸šè–ªé…¬åˆ†ææœ€ç»ˆç»“æœ (Final Results) === ğŸ‰')\n",
    "    print()\n",
    "    \n",
    "    if 'growth_champion' in locals() and growth_champion is not None:\n",
    "        print('ğŸ† å¢é•¿å† å†› (Growth Champion):')\n",
    "        print(f'    {growth_champion[\"IndustryName\"]}')\n",
    "        print(f'    å¢é•¿ç‡: {growth_champion[\"Growth_Rate\"]:.1f}%')\n",
    "        print()\n",
    "    \n",
    "    if 'decline_king' in locals() and decline_king is not None:\n",
    "        print('ğŸ“‰ è¡°é€€ä¹‹ç‹ (Decline King):')\n",
    "        print(f'    {decline_king[\"IndustryName\"]}')\n",
    "        print(f'    å˜åŒ–ç‡: {decline_king[\"Growth_Rate\"]:.1f}%')\n",
    "        print()\n",
    "    \n",
    "    if 'gap_multiplier' in locals() and gap_multiplier is not None:\n",
    "        print('ğŸ“Š è–ªé…¬å·®è·å€æ•° (Salary Gap Multiplier):')\n",
    "        print(f'    {gap_multiplier:.1f}x')\n",
    "        print(f'    (2024å¹´æœ€é«˜è–ªé…¬è¡Œä¸šæ˜¯æœ€ä½è–ªé…¬è¡Œä¸šçš„ {gap_multiplier:.1f} å€)')\n",
    "        print()\n",
    "    \n",
    "    print('=' * 60)\n",
    "    print('âœ… æ•°æ®åˆ†æå®Œæˆï¼è¿™äº›æ•°å­—å¯ä»¥ç”¨äºå‰ç«¯å±•ç¤ºã€‚')\n",
    "    print('ğŸ“Š åˆ†æåŸºäºCBSè·å…°ä¸­å¤®ç»Ÿè®¡å±€2010-2024å¹´æ•°æ®')\n",
    "\n",
    "# æ‰§è¡Œæœ€ç»ˆæ±‡æ€» (Execute final summary)\n",
    "summarize_big_numbers()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
